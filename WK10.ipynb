{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QshK8s21WBrf"
      },
      "source": [
        "# Week 10\n",
        "\n",
        "Text Processing and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hf8SXUwWOho"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Run the following 2 cells to import all necessary libraries and helpers for this week's exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py\n",
        "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/text_utils.py\n",
        "!wget -qO- https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/datasets/text/movie_reviews.tar.gz | tar xz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### All Scikit-Learn Now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from data_utils import MinMaxScaler\n",
        "from data_utils import classification_error, display_confusion_matrix\n",
        "\n",
        "from text_utils import get_top_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Classification\n",
        "\n",
        "Let's try to predict whether a given review expresses positive or negative feelings towards a movie.\n",
        "\n",
        "We have a dataset that basically has $2$ features per record: `review` and `sentiment`.\n",
        "\n",
        "Let's load and look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_df = pd.read_csv(\"./data/text/movie_reviews.csv\")\n",
        "reviews_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Features\n",
        "\n",
        "Text is a very different kind of feature...\n",
        "\n",
        "We do want to turn it into numbers somehow in order to apply some of the methods and models we've been learning about, but how to do that exactly is not entirely obvious.\n",
        "\n",
        "We can try to extract some numerical information about the review text. Maybe something like the length of the review or the relative amount of punctuation marks or digits can be indicative of its sentiment.\n",
        "\n",
        "Let's define some helper functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_characters(st):\n",
        "  return len(\"\".join(st.split()))\n",
        "\n",
        "def count_words(st):\n",
        "  return len(st.split(\" \"))\n",
        "\n",
        "def count_punctuation(st):\n",
        "  return len([c for c in st if c in string.punctuation])\n",
        "\n",
        "def count_digits(st):\n",
        "  return len([c for c in st if c in string.digits])\n",
        "\n",
        "def get_punctuation_pct(st):\n",
        "  return count_punctuation(st) / count_characters(st)\n",
        "\n",
        "def get_digit_pct(st):\n",
        "  return count_digits(st) / count_characters(st)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's apply some of these to our `DataFrame` to create numerical features that we can eventually use in a classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_df[\"char_count\"] = reviews_df[\"review\"].apply(count_characters)\n",
        "reviews_df[\"word_count\"] = reviews_df[\"review\"].apply(count_words)\n",
        "reviews_df[\"punctuation_pct\"] = reviews_df[\"review\"].apply(get_punctuation_pct)\n",
        "reviews_df[\"digit_pct\"] = reviews_df[\"review\"].apply(get_digit_pct)\n",
        "\n",
        "reviews_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we model this data, let's look at some of these features and see if we can visually identify the negative and positive reviews on plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(reviews_df[\"word_count\"], reviews_df[\"punctuation_pct\"], c=reviews_df[\"sentiment\"])\n",
        "plt.title(\"Punctuation % x Word Count\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(reviews_df[\"digit_pct\"], reviews_df[\"punctuation_pct\"], c=reviews_df[\"sentiment\"])\n",
        "plt.title(\"Digit % x Word Count\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(reviews_df[\"word_count\"], reviews_df[\"char_count\"], c=reviews_df[\"sentiment\"])\n",
        "plt.title(\"Character Count x Word Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is not very promising. It doesn't seem like these features contain enough information to help us extract meaning from the reviews.\n",
        "\n",
        "Let's just confirm this suspicion by creating a classifier.\n",
        "\n",
        "We'll use a `MinMaxScaler` since some of the features are already in a $[0,1]$ range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mScaler = MinMaxScaler()\n",
        "\n",
        "simple_feats_df = reviews_df.drop(columns=[\"review\", \"sentiment\"])\n",
        "simple_feats_scaled_df = mScaler.fit_transform(simple_feats_df)\n",
        "\n",
        "simple_feats_scaled_df[\"sentiment\"] = reviews_df[\"sentiment\"]\n",
        "\n",
        "simple_feats_scaled_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train/Test splitting should've been done before scaling, but this is just a quick experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_train_df, reviews_test_df = train_test_split(simple_feats_scaled_df, test_size=0.2)\n",
        "\n",
        "reviews_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mClassifier = RandomForestClassifier()\n",
        "\n",
        "train_feats = reviews_train_df.drop(columns=[\"sentiment\"])\n",
        "train_labels = reviews_train_df[\"sentiment\"]\n",
        "\n",
        "mClassifier.fit(train_feats, train_labels)\n",
        "\n",
        "train_preds = mClassifier.predict(train_feats)\n",
        "\n",
        "classification_error(train_labels, train_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_feats = reviews_test_df.drop(columns=[\"sentiment\"])\n",
        "test_labels = reviews_test_df[\"sentiment\"]\n",
        "\n",
        "test_preds = mClassifier.predict(test_feats)\n",
        "\n",
        "classification_error(test_labels, test_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ¤”\n",
        "\n",
        "Our model is just as good as a random guess.\n",
        "\n",
        "We'll have to use something else.\n",
        "\n",
        "Back to the drawing board."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag-of-Words (BoW)\n",
        "\n",
        "This is a way of modeling sentences as a function of their words. We can think of it as a specialized version of One-Hot encoding, where we turn our single-column `review` feature into a series of numbers that represent which words are present in that review. If a word is not present, that column gets a $0$, if the word is present, the column gets an integer that represents the total number of times that word was used in the review.\n",
        "\n",
        "There are some specificities to keep in mind when we encode text this way. We need to figure out what constitutes a _word_ and what kind of words we want to ignore.\n",
        "\n",
        "Do we consider the words `type`, `types`, `typed` as the same word or $3$ different words ?\n",
        "\n",
        "Do we consider words like `a`, `the`, `of`, `in`, etc ... in our encoding ? What other kinds of words should be treated differently ?\n",
        "\n",
        "The first consideration is part of the process of _Tokenization_, or, how we turn sequences (of words) into its constitutive components (tokens). There are libraries and pre-trained models that can help us with that task.\n",
        "\n",
        "To answer part of the second question: it's best to remove common words from text before processing it because they don't add meaning or variance to our data. These words are commonly referred to as _stop words_, or _negative dictionary_, and, again, we can find lists of common _stop words_ for different languages in text-processing libraries and packages.\n",
        "\n",
        "Our dataset can have other words that show up very frequently, but aren't generally considered _stop words_. For example, a dataset about movie reviews might have the words `movie`, `good`, `director`, etc in every single review. While not typical _stop words_, they should be ignored during encoding because they add no meaningful differentiation to our data.\n",
        "\n",
        "The same is true for words that are rare and only show up in a small fraction of our sentences/reviews.\n",
        "\n",
        "This process of encoding text sequences by the count of their words is called Vectorization. This method of encoding keeps track of which words are present in a series of words, and how common they are, but without any significant information about the order of the words or where they occurred in the original text.\n",
        "\n",
        "That's why models created this way are usually called _Bag-of-Word_ models: they model _what_ words are there, but not _where_ they occurred."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vectorize by Count\n",
        "\n",
        "Let's use the `scikit-learn` class `CountVectorizer` to encode our reviews.\n",
        "\n",
        "The `min_df` and `max_df` parameters to the class constructor determine the minimum and maximum document frequencies to consider when encoding our data.\n",
        "\n",
        "With `min_df=5` and `max_df=0.75`, the vectorizer ignores words that show up in less than $5$ reviews and words that show up in more than $75\\%$ of reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_df = pd.read_csv(\"./data/text/movie_reviews.csv\")\n",
        "\n",
        "reviews_train_df, reviews_test_df = train_test_split(reviews_df, test_size=0.2)\n",
        "reviews_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mCV = CountVectorizer(stop_words=\"english\", min_df=5, max_df=0.75, max_features=10_000)\n",
        "\n",
        "reviews_train_vct = mCV.fit_transform(reviews_train_df[\"review\"])\n",
        "reviews_test_vct = mCV.transform(reviews_test_df[\"review\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we print our encoded features, we should see something like:\n",
        "\n",
        "# TODO: ADD IMAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_train_vct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But we don't.\n",
        "\n",
        "What !?\n",
        "\n",
        "### Sparse Matrices\n",
        "\n",
        "This is why we have to move beyond `DataFrames` for text encoding.\n",
        "\n",
        "We have thousands of reviews and thousands of possible words in our vocabulary. Encoding this information using a `DataFrame` would be extremely inefficient and wasteful because most of the columns for any given row is most likely a $0$. Even if a review used $1\\text{,}000$ unique words, that would still mean that only about $10\\%%$ of our columns would have non-zero values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `CountVectorizer` object has functions that give us information about the words it encountered.\n",
        "\n",
        "`get_feature_names_out()`: returns a list of the words seen in the dataset and encoded.\n",
        "\n",
        "`inverse_transform()`: can be used to turn a sequence of word counts back into actual words, but without the order information of the original sentence.\n",
        "\n",
        "And, we can index into our vector with `[]` to get the counts of specific words in that vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = mCV.get_feature_names_out()\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mCV.inverse_transform(reviews_train_vct[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get indices of words in a review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_train_vct[0].nonzero()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get counts of those words in a review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_train_vct[reviews_train_vct[0].nonzero()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use these functions to order the words of a review by frequency.\n",
        "\n",
        "The process is:\n",
        "\n",
        "- Get a `review` by indexing into our list of encoded reviews\n",
        "- Count the number of tokens/words in the review\n",
        "- Use [argsort()](https://numpy.org/doc/2.1/reference/generated/numpy.argsort.html) to get the order of indices that would sort the word counts\n",
        "  - Use negative counts to get the counts ordered from largest to smallest\n",
        "- Use the first `word_count` items of this array to index into our vocab and get the actual words of the review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "review = reviews_train_vct[0]\n",
        "\n",
        "word_count = len(review.nonzero()[0])\n",
        "\n",
        "sorted_idxs = (-review.toarray()[0]).argsort()\n",
        "\n",
        "vocab[sorted_idxs[:word_count]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This seems like a useful enough operation, that maybe it should be a function that we can use on any sparse matrix of frequency counts...\n",
        "\n",
        "The `get_top_words(cnt, vocab, n)` function will return the top `n` words of `cnt`, a count vector or count matrix (list of vectors). Omitting `n` makes the function return all of the words present in the sequences, ordered by frequency.\n",
        "\n",
        "The returned value is a tuple of words and their counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from text_utils import get_top_words\n",
        "\n",
        "get_top_words(reviews_train_vct[:2], vocab, word_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classifying by Count\n",
        "\n",
        "Ok. After that little bit of a detour to explore vector count sparse matrices, we are back to our classification problem.\n",
        "\n",
        "Can we extract whether a review is positive or negative by looking at the words used ?\n",
        "\n",
        "Let's train a `RandomForestClassifier` and validate with our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mClassifier = RandomForestClassifier()\n",
        "\n",
        "train_labels = reviews_train_df[\"sentiment\"]\n",
        "\n",
        "mClassifier.fit(reviews_train_vct, train_labels)\n",
        "\n",
        "train_preds = mClassifier.predict(reviews_train_vct)\n",
        "\n",
        "classification_error(train_labels, train_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not bad. Promising."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_labels = reviews_test_df[\"sentiment\"]\n",
        "\n",
        "test_preds = mClassifier.predict(reviews_test_vct)\n",
        "\n",
        "classification_error(test_labels, test_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ok! This is not bad. After learning about count vectorization and sparse matrices, the code for doing this is actually quite simple.\n",
        "\n",
        "We could adjust parameters of the classifier or the vectorizer to improve this, but using a `RandomForestClassifier` for this task is quite inefficient. Let's look at a different kind of classifier before we continue exploring vectorization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive Bayes\n",
        "\n",
        "Bayesian statistics is a complete and complex field of math and philosophy. At a high level, it's a theory that allows for probabilities (of events, measurements, classifications, etc) to be updated based on the presence of (new) data.\n",
        "\n",
        "We are going to look at a very slim portion of Bayesian statistics to get a basic understanding of how this theory can be applied within Machine Learning algorithms.\n",
        "\n",
        "The Naive Bayes methods are a set of supervised learning algorithms based on a version of Bayes' theorem that assumes that all of our features are independent.\n",
        "\n",
        "As applied to a classification problem, this theorem has the following form:\n",
        "\n",
        "$$P\\left(y \\middle| x_1, x_2, \\ldots, x_n\\right) = \\frac{P\\left(y\\right)P\\left(x_1, x_2, \\ldots, x_n \\middle| y \\right)}{P\\left(x_1, x_2, \\ldots, x_n\\right)}$$\n",
        "\n",
        "This is an eyeful, but given that $y$ is the class associated with feature measurements $x_1, x_2, \\ldots, x_n$, it reads:\n",
        "\n",
        "The probability that a given set of measurements ($x_1, x_2, \\ldots, x_n$) represents an object of class $y$ is equal to the probability of seeing an object of class $y$ in our dataset, multiplied by the probability that an object of class $y$ has measurements $x_1, x_2, \\ldots, x_n$, divided by how common that particular set of measurements are.\n",
        "\n",
        "$P\\left(y\\right)$ is calculated by measuring how many items of our dataset represent an object of class $y$. If we have $10$ objects that are $y$ in a dataset of $50$ objects, our $P\\left(y\\right) = \\frac{10}{50}$.\n",
        "\n",
        "Likewise, $P\\left(x_1, x_2, \\ldots, x_n\\right)$ represents how many times this exact combination of measurements showed up in our dataset. If only one row out of $50$ has this combination of input features, then $P\\left(x_1, x_2, \\ldots, x_n\\right) = \\frac{1}{50}$.\n",
        "\n",
        "$P\\left(x_1, x_2, \\ldots, x_n \\middle| y \\right)$ is the trickier bit, but it gets simplified by the _naive_ assumption of feature independence and can be split into multiple terms:\n",
        "\n",
        "$P\\left(x_1 \\middle| y \\right) \\cdot P\\left(x_2 \\middle| y \\right) \\cdot\\ldots\\cdot P\\left(x_n \\middle| y \\right)$\n",
        "\n",
        "These are the probabilities that items of class $y$ have specific values for $x_1, x_2, \\ldots x_n$. For example, if in our dataset of $50$ elements, $10$ have class $y$, and $2$ out of those $10$ have a particular value $x_1$ for the first feature, $P\\left(x_1 \\middle| y \\right) = \\frac{2}{10}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Naive Bayes Text Example\n",
        "\n",
        "Let's pretend we want to calculate the probability that a review with the words `awful`, `bloody`, `guns` and `park` is **negative**.\n",
        "\n",
        "This is equivalent to calculating:\n",
        "$$P\\left(negative \\middle| \\text{awful}, \\text{bloody}, \\text{guns}, \\text{park} \\right) = \\frac{P\\left(negative\\right) P\\left(\\text{awful}, \\text{bloody}, \\text{guns}, \\text{park} \\middle| negative \\right)}{P\\left(\\text{awful}, \\text{bloody}, \\text{guns}, \\text{park}\\right)}$$\n",
        "\n",
        "$P\\left(\\text{negative}\\right)$ is equal to the proportion of **negative** reviews in the dataset. If half are positive and half are negative, $P\\left(\\text{negative}\\right) = 0.5$.\n",
        "\n",
        "$P\\left(\\text{awful}, \\text{bloody}, \\text{guns}, \\text{park}\\right)$ is the proportion of the number of reviews in the dataset that got vectorized using the words `awful`, `bloody`, `guns` and `park`.\n",
        "\n",
        "$P\\left(\\text{awful}, \\text{bloody}, \\text{guns}, \\text{park} \\middle| negative \\right)$ can be simplified to $P\\left(\\text{awful} \\middle| negative \\right) \\cdot P\\left(\\text{bloody} \\middle| negative \\right) \\cdot P\\left(\\text{guns} \\middle| negative \\right) \\cdot P\\left(\\text{park} \\middle| negative \\right)$\n",
        "\n",
        "$P\\left(\\text{awful} \\middle| negative \\right)$ is the proportion of negative reviews that have the word `awful`, $P\\left(\\text{bloody} \\middle| y \\right)$ is the proportion of negative review with `bloody` in it, etc etc etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why ????\n",
        "\n",
        "It might not be obvious at first, but when used for classification of datasets with sparse feature vectors, the process described above can be extremely efficient because _fitting_ the model means calculating a few probability constants from our training dataset. All of the $P()$ terms on the right hand side of the Bayes equation are basic proportions calculated with addition and division operations.\n",
        "\n",
        "`Scikit-Learn` has different flavors of Naive Bayes classifiers that make further assumptions about the distributions of the input features and how $P\\left(X \\middle| y \\right)$ can be simplified.\n",
        "\n",
        "- [Gaussian](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) Naive Bayes assumes the features have gaussian distributions. This is good for datasets with continuous-valued inputs.\n",
        "- [Bernoulli](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html) Naive Bayes assumes the features are all binary values (One-Hot Encoding).\n",
        "- [Categorical](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html) Naive Bayes assumes our features are integers that represent categories (Ordinal Encoding).\n",
        "- [Multinomial](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) Naive Bayes assumes our features are discrete measurements.\n",
        "\n",
        "Given that the feature vectors computed with `CountVectorizer` represent word counts, it makes sense for us to use a Multinomial classifier for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: repeat classification using the appropriate Bayes model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### N-Grams\n",
        "\n",
        "Now that we have an efficient classifier for sparse count feature vectors we can finally experiment with n-grams.\n",
        "\n",
        "In its simplest form, the Bag-of-Words method doesn't take into consideration any information about the order or location of the words in a sequence of words. We can, however, set it up to count pairs (or triplets, or quadruplets, etc) of words instead of single words.\n",
        "\n",
        "So, instead of breaking up \"_it was a good movie_\", like this:\n",
        "|it|was|a|good|movie|\n",
        "|-|-|-|-|-|\n",
        "\n",
        "It breaks it up like this:\n",
        "\n",
        "|it was|was a|a good|good movie|\n",
        "|-|-|-|-|\n",
        "\n",
        "These are the 2-grams (or bi-grams) of our sentence, but the concept can be extended to any integer value of $n$ to extract counts for different lengths of n-grams.\n",
        "\n",
        "While this doesn't help with location information, it does extract some information about word order and common phrases.\n",
        "\n",
        "To extract n-grams during vectorization, we can give `CountVectorizer` a range of values to consider with the parameter `ngram_range`. A value of $(2,2)$ will only extract bigrams, while $(1,2)$ will extract counts for single words and pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mCV = CountVectorizer(stop_words=\"english\", min_df=5, max_df=0.75, max_features=50_000, ngram_range=(2, 2))\n",
        "\n",
        "reviews_train_vct = mCV.fit_transform(reviews_train_df[\"review\"])\n",
        "reviews_test_vct = mCV.transform(reviews_test_df[\"review\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `CountVectorizer` functions we saw above and our `get_top_words()` function will work the same way. The only difference is that right now our features are counts of pairs of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = mCV.get_feature_names_out()\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mCV.inverse_transform(reviews_train_vct[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_top_words(reviews_train_vct[0], vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and Validate\n",
        "\n",
        "Let's try it out !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mClassifier = MultinomialNB()\n",
        "\n",
        "train_labels = reviews_train_df[\"sentiment\"]\n",
        "\n",
        "mClassifier.fit(reviews_train_vct, train_labels)\n",
        "\n",
        "train_preds = mClassifier.predict(reviews_train_vct)\n",
        "\n",
        "classification_error(train_labels, train_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_labels = reviews_test_df[\"sentiment\"]\n",
        "\n",
        "test_preds = mClassifier.predict(reviews_test_vct)\n",
        "\n",
        "classification_error(test_labels, test_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TF-IDF\n",
        "\n",
        "# TODO HERE\n",
        "\n",
        "$$tf(t, d) = \\frac{Count(t)}{| d |}$$\n",
        "\n",
        "$$idf(t, D) = log\\left(\\frac{|D|}{Count(d : t \\in d)}\\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mTfidV = TfidfVectorizer(stop_words=\"english\", min_df=5, max_df=0.75, max_features=50_000, ngram_range=(1, 1))\n",
        "\n",
        "reviews_train_vct = mTfidV.fit_transform(reviews_train_df[\"review\"])\n",
        "reviews_test_vct = mTfidV.transform(reviews_test_df[\"review\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And again, the `TfidfVectorizer` has all the functions we saw above in the `CountVectorizer` object and our `get_top_words()` function will work the same way with our tf-idf vectors. The difference is that now our features are not plain integer counts of words or n-grams, but our tf-idf importance metric. The higher the metric, the more significant the word (or n-gram) within our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = mTfidV.get_feature_names_out()\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mTfidV.inverse_transform(reviews_train_vct[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_top_words(reviews_train_vct[0], vocab, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification with tf-idf\n",
        "\n",
        "This stays the same. While the multinomial classifier normally requires integer features, in practice, fractional counts such as the ones computed with a `TfidfVectorizer` also work. We can always turn these into `int` by multiplying them by $100$. The main distinction is that these aren't continuous unbounded `float` values. It wouldn't make sense to use the Gaussian Bayes classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mClassifier = MultinomialNB()\n",
        "\n",
        "train_labels = reviews_train_df[\"sentiment\"]\n",
        "\n",
        "mClassifier.fit(reviews_train_vct, train_labels)\n",
        "\n",
        "train_preds = mClassifier.predict(reviews_train_vct)\n",
        "\n",
        "classification_error(train_labels, train_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_labels = reviews_test_df[\"sentiment\"]\n",
        "\n",
        "test_preds = mClassifier.predict(reviews_test_vct)\n",
        "\n",
        "classification_error(test_labels, test_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not bad.\n",
        "\n",
        "How does the choice of n-gram range affect classification by tf-idf ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Evaluate the effect of n-grams in the TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unsupervised Learning\n",
        "\n",
        "# TODO\n",
        "\n",
        "Can we extract other info ? Cluster ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mClust = KMeans(n_clusters=8)\n",
        "reviews_train_km = mClust.fit_predict(reviews_train_vct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_top_words(mClust.cluster_centers_, mTfidV.get_feature_names_out(), 8)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can we do better ?\n",
        "\n",
        "We're clustering over 40k features .... very sparse space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mNmf = NMF(n_components=8)\n",
        "reviews_train_nmf = mNmf.fit_transform(reviews_train_vct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_top_words(mNmf.components_, mTfidV.get_feature_names_out(), 6)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification for other dataset.\n",
        "\n",
        "Amazon products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -qO- https://github.com/PSAM-5020-2025S-A/5020-utils/raw/refs/heads/main/datasets/text/amazon_reviews/books.tar.gz | tar xz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read and drop nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_full_df = pd.read_csv(\"./data/text/amazon_reviews/books.csv\")\n",
        "reviews_full_df.dropna(inplace=True)\n",
        "reviews_full_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Look at class distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_full_df[\"rating\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ«¤\n",
        "\n",
        "A model can guess $5$ all the time and be correct $60\\%$ of the time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_count = reviews_full_df[\"rating\"].value_counts().min()\n",
        "\n",
        "def sample_min(df):\n",
        "  return df.sample(min_count)\n",
        "\n",
        "rg = reviews_full_df.groupby(\"rating\")\n",
        "reviews_balanced_df = rg.apply(sample_min).reset_index(drop=True)\n",
        "\n",
        "del reviews_full_df\n",
        "\n",
        "reviews_balanced_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Two more prep steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_df = pd.DataFrame(reviews_balanced_df[\"rating\"].astype(int))\n",
        "reviews_df[\"review\"] = reviews_balanced_df[\"title\"] + \" \" + reviews_balanced_df[\"review_text\"]\n",
        "reviews_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ok. Go forth and Classify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T/T Split\n",
        "# Vectorize\n",
        "# Classify\n",
        "# Evaluate\n",
        "# Repeat with ngrams"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.17 ('hf-model')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
